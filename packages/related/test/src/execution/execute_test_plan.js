/*
 *
 */

import { existsSync } from "node:fs";
import { takeCoverage } from "node:v8";
import stripAnsi from "strip-ansi";
import { Abort, raceProcessTeardownEvents } from "@jsenv/abort";
import { URL_META } from "@jsenv/url-meta";
import {
  ensureEmptyDirectory,
  assertAndNormalizeDirectoryUrl,
  collectFiles,
} from "@jsenv/filesystem";
import { createLogger, createDetailedMessage, UNICODE } from "@jsenv/log";
import {
  startGithubCheckRun,
  readGitHubWorkflowEnv,
} from "@jsenv/github-check-run";

import { startMeasuringCpuUsage } from "../helpers/cpu_usage.js";
import { createCallOrderer } from "../helpers/call_orderer.js";
import { reportToCoverage } from "../coverage/report_to_coverage.js";
import { assertAndNormalizeWebServer } from "./web_server_param.js";
import { githubAnnotationFromError } from "./github_annotation_from_error.js";
import { run } from "./run.js";
import { listReporter, renderFinalSummary } from "./reporters/reporter_list.js";

/**
 * Execute a list of files and log how it goes.
 * @param {Object} testPlanParameters
 * @param {string|url} testPlanParameters.rootDirectoryUrl Directory containing test files;
 * @param {Object} [testPlanParameters.webServer] Web server info; required when executing test on browsers
 * @param {Object} testPlanParameters.testPlan Object associating files with runtimes where they will be executed
 * @param {boolean|number} [testPlanParameters.concurrency=false] Maximum amount of execution running at the same time
 * @param {number} [testPlanParameters.defaultMsAllocatedPerExecution=30000] Milliseconds after which execution is aborted and considered as failed by timeout
 * @param {boolean} [testPlanParameters.failFast=false] Fails immediatly when a test execution fails
 * @param {boolean} [testPlanParameters.logMemoryUsage=false] Add memory heap usage during logs
 * @param {boolean} [testPlanParameters.coverageEnabled=false] Controls if coverage is collected during files executions
 * @param {boolean} [testPlanParameters.coverageV8ConflictWarning=true] Warn when coverage from 2 executions cannot be merged
 * @return {Object} An object containing the result of all file executions
 */
const logsDefault = {
  level: "info",
  dynamic: true,
  memoryUsage: true,
  fileUrl: undefined,
};
const githubCheckDefault = {
  logLevel: "info",
  name: "Jsenv tests",
  title: "Tests execution",
  token: undefined,
  repositoryOwner: undefined,
  repositoryName: undefined,
  commitSha: undefined,
};
const coverageDefault = {
  include: {
    "file:///**/node_modules/": false,
    "./**/.*": false,
    "./**/.*/": false,
    "./**/src/**/*.js": true,
    "./**/src/**/*.ts": true,
    "./**/src/**/*.jsx": true,
    "./**/src/**/*.tsx": true,
    "./**/tests/": false,
    "./**/*.test.html": false,
    "./**/*.test.html@*.js": false,
    "./**/*.test.js": false,
    "./**/*.test.mjs": false,
  },
  includeMissing: true,
  coverageAndExecutionAllowed: false,
  methodForNodeJs: process.env.NODE_V8_COVERAGE
    ? "NODE_V8_COVERAGE"
    : "Profiler",
  // - When chromium only -> coverage generated by v8
  // - When chromium + node -> coverage generated by v8 are merged
  // - When firefox only -> coverage generated by babel+istanbul
  // - When chromium + firefox
  //   -> by default only coverage from chromium is used
  //   and a warning is logged according to coverageV8ConflictWarning
  //   -> to collect coverage from both browsers, pass coverageMethodForBrowsers: "istanbul"
  methodForBrowsers: undefined, // undefined | "playwright" | "istanbul"
  v8ConflictWarning: true,
  tempDirectoryUrl: undefined,
};
const parallelDefault = {
  max: 5, // "50%",
  maxCpu: "50%",
  maxMemory: "50%",
};

export const executeTestPlan = async ({
  logs = logsDefault,

  rootDirectoryUrl,
  webServer,
  testPlan,

  signal = new AbortController().signal,
  handleSIGINT = true,
  updateProcessExitCode = true,
  parallel = parallelDefault,
  defaultMsAllocatedPerExecution = 30_000,
  failFast = false,
  // keepRunning: false to ensure runtime is stopped once executed
  // because we have what we wants: execution is completed and
  // we have associated coverage and console output
  // passsing true means all node process and browsers launched stays opened
  // (can eventually be used for debug)
  keepRunning = false,

  githubCheck = process.env.GITHUB_WORKFLOW ? githubCheckDefault : null,
  coverage = process.argv.includes("--coverage") ? coverageDefault : null,

  reporters = [],
  ...rest
}) => {
  const teardownCallbackSet = new Set();

  const operation = Abort.startOperation();
  operation.addAbortSignal(signal);
  if (handleSIGINT) {
    operation.addAbortSource((abort) => {
      return raceProcessTeardownEvents(
        {
          SIGINT: true,
        },
        () => {
          logger.debug(`SIGINT abort`);
          abort();
        },
      );
    });
  }

  const cpuUsage = startMeasuringCpuUsage();
  operation.addEndCallback(cpuUsage.stop);

  let logger;
  let someNeedsServer = false;
  let someHasCoverageV8 = false;
  let someNodeRuntime = false;
  const runtimes = {};
  // param validation
  {
    const unexpectedParamNames = Object.keys(rest);
    if (unexpectedParamNames.length > 0) {
      throw new TypeError(`${unexpectedParamNames.join(",")}: no such param`);
    }
    rootDirectoryUrl = assertAndNormalizeDirectoryUrl(
      rootDirectoryUrl,
      "rootDirectoryUrl",
    );
    if (!existsSync(new URL(rootDirectoryUrl))) {
      throw new Error(`ENOENT on rootDirectoryUrl at ${rootDirectoryUrl}`);
    }
    if (typeof testPlan !== "object") {
      throw new Error(`testPlan must be an object, got ${testPlan}`);
    }

    if (typeof logs !== "object") {
      throw new TypeError(`logs must be an object, got ${logs}`);
    }

    const unexpectedLogsKeys = Object.keys(logs).filter(
      (key) => !Object.hasOwn(logsDefault, key),
    );
    if (unexpectedLogsKeys.length > 0) {
      throw new TypeError(
        `${unexpectedLogsKeys.join(",")}: no such key on logs`,
      );
    }
    Object.assign(logs, logsDefault);

    logger = createLogger({ logLevel: logs.level });

    for (const filePattern of Object.keys(testPlan)) {
      const filePlan = testPlan[filePattern];
      if (!filePlan) continue;
      for (const executionName of Object.keys(filePlan)) {
        const executionConfig = filePlan[executionName];
        const { runtime } = executionConfig;
        if (!runtime || runtime.disabled) {
          continue;
        }
        runtimes[runtime.name] = runtime.version;
        if (runtime.type === "browser") {
          if (runtime.capabilities && runtime.capabilities.coverageV8) {
            someHasCoverageV8 = true;
          }
          someNeedsServer = true;
        }
        if (runtime.type === "node") {
          someNodeRuntime = true;
        }
      }
    }

    if (someNeedsServer) {
      await assertAndNormalizeWebServer(webServer, {
        signal: operation.signal,
        teardownCallbackSet,
        logger,
      });
    }

    if (githubCheck && !process.env.GITHUB_TOKEN) {
      githubCheck = false;
      const suggestions = [];
      if (process.env.GITHUB_WORKFLOW_REF) {
        const workflowFileRef = process.env.GITHUB_WORKFLOW_REF;
        const refsIndex = workflowFileRef.indexOf("@refs/");
        // see "GITHUB_WORKFLOW_REF" in https://docs.github.com/en/actions/learn-github-actions/variables#default-environment-variables
        const workflowFilePath =
          refsIndex === -1
            ? workflowFileRef
            : workflowFileRef.slice(0, refsIndex);
        suggestions.push(`Pass github token in ${workflowFilePath} during job "${process.env.GITHUB_JOB}"
\`\`\`yml
env:
  GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}
\`\`\``);
      }
      suggestions.push(`Disable github check with githubCheck: false`);
      logger.warn(
        `${UNICODE.WARNING} githubCheck requires process.env.GITHUB_TOKEN.
Integration with Github check API is disabled
To fix this warning:
- ${suggestions.join("\n- ")}
`,
      );
    }
    if (githubCheck) {
      if (typeof githubCheck !== "object") {
        throw new TypeError(`coverage must be an object, got ${coverage}`);
      }
      const unexpectedKeys = Object.keys(githubCheck).filter(
        (key) => !Object.hasOwn(githubCheckDefault, key),
      );
      if (unexpectedKeys.length > 0) {
        throw new TypeError(
          `${unexpectedKeys.join(",")}: no such key on githubCheck`,
        );
      }

      const githubCheckInfoFromEnv = process.env.GITHUB_WORKFLOW
        ? readGitHubWorkflowEnv()
        : {};
      Object.assign(githubCheck, githubCheckDefault);
      if (githubCheck.token === undefined) {
        githubCheck.token = githubCheckInfoFromEnv.githubToken;
      }
      if (githubCheck.repositoryOwner === undefined) {
        githubCheck.repositoryOwner = githubCheckInfoFromEnv.repositoryOwner;
      }
      if (githubCheck.repositoryName === undefined) {
        githubCheck.repositoryName = githubCheckInfoFromEnv.repositoryName;
      }
      if (githubCheck.commitSha === undefined) {
        githubCheck.commitSha = githubCheckInfoFromEnv.commitSha;
      }
    }

    if (coverage) {
      if (typeof coverage !== "object") {
        throw new TypeError(`coverage must be an object, got ${coverage}`);
      }

      const unexpectedKeys = Object.keys(coverage).filter(
        (key) => !Object.hasOwn(coverageDefault, key),
      );
      if (unexpectedKeys.length > 0) {
        throw new TypeError(
          `${unexpectedKeys.join(",")}: no such key on coverage`,
        );
      }
      Object.assign(coverage, coverageDefault);
      if (coverage.methodForBrowsers === undefined) {
        coverage.methodForBrowsers = someHasCoverageV8
          ? "playwright"
          : "istanbul";
      }
      if (typeof coverage.include !== "object") {
        throw new TypeError(
          `coverage.include must be an object, got ${coverage.include}`,
        );
      }
      if (!coverage.coverageAndExecutionAllowed) {
        const associationsForExecute = URL_META.resolveAssociations(
          { execute: testPlan },
          "file:///",
        );
        const associationsForCover = URL_META.resolveAssociations(
          { cover: coverage.include },
          "file:///",
        );
        const patternsMatchingCoverAndExecute = Object.keys(
          associationsForExecute.execute,
        ).filter((testPlanPattern) => {
          const { cover } = URL_META.applyAssociations({
            url: testPlanPattern,
            associations: associationsForCover,
          });
          return cover;
        });
        if (patternsMatchingCoverAndExecute.length) {
          // It would be strange, for a given file to be both covered and executed
          throw new Error(
            createDetailedMessage(
              `some file will be both covered and executed`,
              {
                patterns: patternsMatchingCoverAndExecute,
              },
            ),
          );
        }
      }
      if (coverage.tempDirectoryUrl === undefined) {
        coverage.tempDirectoryUrl = new URL(
          "./.coverage/tmp/",
          rootDirectoryUrl,
        );
      } else {
        coverage.tempDirectoryUrl = assertAndNormalizeDirectoryUrl(
          coverage.tempDirectoryUrl,
          "coverageTempDirectoryUrl",
        );
      }
    }
  }

  logger.debug(
    createDetailedMessage(`Prepare executing plan`, {
      runtimes: JSON.stringify(runtimes, null, "  "),
    }),
  );

  // param normalization
  {
    if (logs.fileUrl === undefined) {
      logs.fileUrl = new URL(
        "./.jsenv/jsenv_tests_output.txt",
        rootDirectoryUrl,
      );
    }
    if (coverage) {
      if (Object.keys(coverage.include).length === 0) {
        logger.warn(
          `coverageConfig is an empty object. Nothing will be instrumented for coverage so your coverage will be empty`,
        );
      }
      if (someNodeRuntime && coverage.methodForNodeJs === "NODE_V8_COVERAGE") {
        if (process.env.NODE_V8_COVERAGE) {
          // when runned multiple times, we don't want to keep previous files in this directory
          await ensureEmptyDirectory(process.env.NODE_V8_COVERAGE);
        } else {
          coverage.methodForNodeJs = "Profiler";
          logger.warn(
            createDetailedMessage(
              `process.env.NODE_V8_COVERAGE is required to generate coverage for Node.js subprocesses`,
              {
                "suggestion": `set process.env.NODE_V8_COVERAGE`,
                "suggestion 2": `use coverage.methodForNodeJs: "Profiler". But it means coverage for child_process and worker_thread cannot be collected`,
              },
            ),
          );
        }
      }
    }
  }

  reporters.push(
    listReporter({
      logger,
      logDynamic: logs.dynamic,
      logMemoryUsage: logs.memoryUsage,
      logFileUrl: logs.fileUrl,
    }),
  );

  testPlan = {
    "file:///**/node_modules/": null,
    "**/*./": null,
    ...testPlan,
    "**/.jsenv/": null,
  };
  logger.debug(`Generate executions`);

  const testPlanResult = {
    rootDirectoryUrl: String(rootDirectoryUrl),
    counters: {
      planified: 0,
      remaining: 0,
      executing: 0,
      executed: 0,

      aborted: 0,
      timedout: 0,
      failed: 0,
      completed: 0,
    },
    aborted: false,
    failed: false,
    results: {},
    duration: 0,
    coverage: null,
  };
  const counters = testPlanResult.counters;
  const results = testPlanResult.results;
  const executionPlanifiedSet = new Set();

  // collect files to execute + fill executionPlanifiedSet
  {
    let fileResultArray;
    try {
      fileResultArray = await collectFiles({
        signal,
        directoryUrl: rootDirectoryUrl,
        associations: { testPlan },
        predicate: ({ testPlan }) => testPlan,
      });
    } catch (e) {
      if (Abort.isAbortError(e)) {
        testPlanResult.aborted = true;
        return testPlanResult;
      }
      throw e;
    }
    let index = 0;
    let lastExecution;
    for (const { relativeUrl, meta } of fileResultArray) {
      const filePlan = meta.testPlan;
      for (const executionName of Object.keys(filePlan)) {
        const stepConfig = filePlan[executionName];
        if (stepConfig === null || stepConfig === undefined) {
          continue;
        }
        if (typeof stepConfig !== "object") {
          throw new TypeError(
            createDetailedMessage(
              `found unexpected value in plan, they must be object`,
              {
                ["file relative path"]: relativeUrl,
                ["execution name"]: executionName,
                ["value"]: stepConfig,
              },
            ),
          );
        }
        if (stepConfig.runtime?.disabled) {
          continue;
        }

        const { runtime, runtimeParams } = stepConfig;
        const params = {
          measureMemoryUsage: logs.memoryUsage,
          measurePerformance: false,
          collectPerformance: false,
          collectConsole: true,
          allocatedMs: defaultMsAllocatedPerExecution,
          runtime,
          runtimeParams: {
            rootDirectoryUrl,
            webServer,

            coverageEnabled: Boolean(coverage),
            coverageConfig: coverage.include,
            coverageMethodForBrowsers: coverage.methodForBrowsers,
            coverageMethodForNodeJs: coverage.methodForNodeJs,
            isTestPlan: true,
            fileRelativeUrl: relativeUrl,
            ...runtimeParams,
          },
        };
        const runtimeType = runtime.type;
        const runtimeName = runtime.name;
        const runtimeVersion = runtime.version;

        const execution = {
          counters,
          index,
          isLast: false,
          name: executionName,
          fileRelativeUrl: relativeUrl,
          runtimeType,
          runtimeName,
          runtimeVersion,
          params,

          // will be set by run()
          status: "planified",
          result: {},
        };
        if (typeof params.allocatedMs === "function") {
          params.allocatedMs = params.allocatedMs(execution);
        }

        lastExecution = execution;
        executionPlanifiedSet.add(execution);
        const existingResults = results[relativeUrl];
        if (existingResults) {
          existingResults[execution.name] = execution.result;
        } else {
          results[relativeUrl] = {
            [execution.name]: execution.result,
          };
        }
        index++;
      }
    }
    if (lastExecution) {
      lastExecution.isLast = true;
    }
  }

  counters.planified = executionPlanifiedSet.size;
  logger.debug(`${executionPlanifiedSet.size} executions planned`);
  if (githubCheck) {
    const githubCheckRun = await startGithubCheckRun({
      logLevel: githubCheck.logLevel,
      githubToken: githubCheck.token,
      repositoryOwner: githubCheck.repositoryOwner,
      repositoryName: githubCheck.repositoryName,
      commitSha: githubCheck.commitSha,
      checkName: githubCheck.name,
      checkTitle: githubCheck.title,
      checkSummary: `${executionPlanifiedSet.size} files will be executed`,
    });
    const annotations = [];
    reporters.push({
      beforeAllExecution: (testPlanReport) => {
        return async () => {
          const title = "Jsenv test results";
          const summaryText = stripAnsi(renderFinalSummary(testPlanReport));
          if (testPlanReport.failed) {
            await githubCheckRun.fail({
              title,
              summary: summaryText,
              annotations,
            });
            return;
          }
          await githubCheckRun.pass({
            title,
            summary: summaryText,
            annotations,
          });
        };
      },
      beforeExecution: (executionInfo) => {
        return () => {
          const { result } = executionInfo;
          const { errors = [] } = result;
          for (const error of errors) {
            const annotation = githubAnnotationFromError(error, {
              rootDirectoryUrl,
              executionInfo,
            });
            annotations.push(annotation);
          }
        };
      },
    });
  }

  const afterAllExecutionCallbackSet = new Set();
  // execute all
  {
    const multipleExecutionsOperation = Abort.startOperation();
    multipleExecutionsOperation.addAbortSignal(signal);
    const failFastAbortController = new AbortController();
    if (failFast) {
      multipleExecutionsOperation.addAbortSignal(
        failFastAbortController.signal,
      );
    }
    let finalizeCoverage;
    if (coverage) {
      // when runned multiple times, we don't want to keep previous files in this directory
      await ensureEmptyDirectory(coverage.tempDirectoryUrl);
      finalizeCoverage = async () => {
        if (multipleExecutionsOperation.signal.aborted) {
          // don't try to do the coverage stuff
          return;
        }
        try {
          if (coverage.methodForNodeJs === "NODE_V8_COVERAGE") {
            takeCoverage();
            // conceptually we don't need coverage anymore so it would be
            // good to call v8.stopCoverage()
            // but it logs a strange message about "result is not an object"
          }
          const testPlanCoverage = await reportToCoverage(results, {
            signal: multipleExecutionsOperation.signal,
            logger,
            rootDirectoryUrl,
            coverageConfig: coverage.include,
            coverageIncludeMissing: coverage.includeMissing,
            coverageMethodForNodeJs: coverage.methodForNodeJs,
            coverageV8ConflictWarning: coverage.v8ConflictWarning,
          });
          testPlanResult.coverage = testPlanCoverage;
        } catch (e) {
          if (Abort.isAbortError(e)) {
            return;
          }
          throw e;
        }
      };
    }

    const callWhenPreviousExecutionAreDone = createCallOrderer();

    const executionRemainingSet = new Set(executionPlanifiedSet);
    const executionExecutingSet = new Set();
    const start = async (execution) => {
      counters.executing++;
      execution.status = "executing";
      executionRemainingSet.delete(execution);
      executionExecutingSet.add(execution);
      const afterExecutionCallbackSet = new Set();
      const afterExecutionInOrderCallbackSet = new Set();
      for (const reporter of reporters) {
        const { beforeExecution } = reporter;
        if (beforeExecution) {
          const returnValue = beforeExecution(execution, testPlanResult);
          if (typeof returnValue === "function") {
            afterExecutionCallbackSet.add(returnValue);
          }
        }
        const { beforeExecutionInOrder } = reporter;
        if (beforeExecutionInOrder) {
          const returnValue = beforeExecutionInOrder(execution, testPlanResult);
          if (typeof returnValue === "function") {
            afterExecutionInOrderCallbackSet.add(returnValue);
          }
        }
      }

      const fileUrl = `${rootDirectoryUrl}${execution.fileRelativeUrl}`;
      if (existsSync(new URL(fileUrl))) {
        const executionResult = await run({
          ...execution.params,
          signal: multipleExecutionsOperation.signal,
          logger,
          keepRunning,
          mirrorConsole: false, // might be executed in parallel: log would be a mess to read
          coverageEnabled: Boolean(coverage),
          coverageTempDirectoryUrl: coverage.tempDirectoryUrl,
        });
        Object.assign(execution.result, executionResult);
      } else {
        execution.result.status = "failed";
        execution.result.errors = [
          new Error(
            `No file at ${execution.fileRelativeUrl} for execution "${execution.name}"`,
          ),
        ];
      }
      execution.status = "executed";
      executionExecutingSet.delete(execution);
      counters.executing--;
      counters.executed++;
      counters.remaining--;
      if (execution.result.status === "aborted") {
        counters.aborted++;
      } else if (execution.result.status === "timedout") {
        counters.timedout++;
      } else if (execution.result.status === "failed") {
        counters.failed++;
      } else if (execution.result.status === "completed") {
        counters.completed++;
      }
      for (const afterExecutionCallback of afterExecutionCallbackSet) {
        afterExecutionCallback();
      }
      afterExecutionCallbackSet.clear();
      callWhenPreviousExecutionAreDone(execution.index, () => {
        for (const afterExecutionInOrderCallback of afterExecutionInOrderCallbackSet) {
          afterExecutionInOrderCallback();
        }
        afterExecutionInOrderCallbackSet.clear();
      });

      if (execution.result.status !== "completed") {
        testPlanResult.failed = true;
        if (updateProcessExitCode) {
          process.exitCode = 1;
        }
        if (failFast && counters.remaining) {
          logger.info(`"failFast" enabled -> cancel remaining executions`);
          failFastAbortController.abort();
        }
      }
    };
    const startAsMuchAsPossible = async () => {
      const promises = [];
      // eslint-disable-next-line no-constant-condition
      while (true) {
        if (multipleExecutionsOperation.signal.aborted) {
          break;
        }
        if (executionExecutingSet.size >= parallel.max) {
          break;
        }
        if (
          // cpu limitation applies only if we try to execute
          // in parallel. If nothing is currently executing we'll
          // keep going
          executionExecutingSet.size > 0 &&
          cpuUsage.overall.active > parallel.maxCpu
        ) {
          // retry after Xms in case cpu usage decreases
          const promise = (async () => {
            await new Promise((resolve) => setTimeout(resolve, 200));
            await startAsMuchAsPossible();
          })();
          promises.push(promise);
          break;
        }

        let execution;
        for (const executionCandidate of executionRemainingSet) {
          // TODO: this is where we'll check if it can be executed
          // according to upcoming "using" execution param
          execution = executionCandidate;
          break;
        }
        if (execution) {
          promises.push(start(execution));
        }
      }
      if (promises.length) {
        await Promise.all(promises);
        promises.length = 0;
      }
    };

    try {
      const startMs = Date.now();
      for (const reporter of reporters) {
        const beforeAllExecution = reporter.beforeAllExecution;
        if (beforeAllExecution) {
          const returnValue = beforeAllExecution(testPlanResult);
          if (typeof returnValue === "function") {
            afterAllExecutionCallbackSet.add(returnValue);
          }
        }
      }
      await startAsMuchAsPossible();
      if (!keepRunning) {
        logger.debug("trigger test plan teardown");
        for (const teardownCallback of teardownCallbackSet) {
          await teardownCallback();
        }
        teardownCallbackSet.clear();
      }
      // when execution is aborted, the remaining executions are "cancelled"
      counters.cancelled = counters.planified - counters.executed;
      testPlanResult.aborted = multipleExecutionsOperation.signal.aborted;
      testPlanResult.duration = Date.now() - startMs;
      if (finalizeCoverage) {
        await finalizeCoverage();
      }
    } finally {
      await multipleExecutionsOperation.end();
    }
  }

  for (const afterAllExecutionCallback of afterAllExecutionCallbackSet) {
    await afterAllExecutionCallback(testPlanResult);
  }
  afterAllExecutionCallbackSet.clear();
  return testPlanResult;
};
