/*
 *
 */

import os from "node:os";
import { existsSync } from "node:fs";
import { takeCoverage } from "node:v8";
import stripAnsi from "strip-ansi";
import { Abort, raceProcessTeardownEvents } from "@jsenv/abort";
import { URL_META } from "@jsenv/url-meta";
import { urlToFileSystemPath, urlToRelativeUrl } from "@jsenv/urls";
import {
  ensureEmptyDirectory,
  assertAndNormalizeDirectoryUrl,
  assertAndNormalizeFileUrl,
  collectFiles,
} from "@jsenv/filesystem";
import { createLogger, createDetailedMessage, UNICODE } from "@jsenv/log";
import {
  startGithubCheckRun,
  readGitHubWorkflowEnv,
} from "@jsenv/github-check-run";

import { reportToCoverage } from "../coverage/report_to_coverage.js";
import { generateCoverageJsonFile } from "../coverage/coverage_reporter_json_file.js";
import { generateCoverageHtmlDirectory } from "../coverage/coverage_reporter_html_directory.js";
import { generateCoverageTextLog } from "../coverage/coverage_reporter_text_log.js";
import { assertAndNormalizeWebServer } from "./web_server_param.js";
import { githubAnnotationFromError } from "./github_annotation_from_error.js";
import { run } from "./run.js";
import { listReporter, renderFinalSummary } from "./reporters/reporter_list.js";

/**
 * Execute a list of files and log how it goes.
 * @param {Object} testPlanParameters
 * @param {string|url} testPlanParameters.rootDirectoryUrl Directory containing test files;
 * @param {Object} [testPlanParameters.webServer] Web server info; required when executing test on browsers
 * @param {Object} testPlanParameters.testPlan Object associating files with runtimes where they will be executed
 * @param {boolean} [testPlanParameters.logShortForCompletedExecutions=false] Abbreviate completed execution information to shorten terminal output
 * @param {boolean} [testPlanParameters.logMergeForCompletedExecutions=false] Merge completed execution logs to shorten terminal output
 * @param {boolean|number} [testPlanParameters.concurrency=false] Maximum amount of execution running at the same time
 * @param {number} [testPlanParameters.defaultMsAllocatedPerExecution=30000] Milliseconds after which execution is aborted and considered as failed by timeout
 * @param {boolean} [testPlanParameters.failFast=false] Fails immediatly when a test execution fails
 * @param {boolean} [testPlanParameters.logMemoryHeapUsage=false] Add memory heap usage during logs
 * @param {boolean} [testPlanParameters.coverageEnabled=false] Controls if coverage is collected during files executions
 * @param {boolean} [testPlanParameters.coverageV8ConflictWarning=true] Warn when coverage from 2 executions cannot be merged
 * @return {Object} An object containing the result of all file executions
 */
export const executeTestPlan = async ({
  logLevel = "info",
  logDynamic,
  logMemoryHeapUsage = true,
  logFileUrl,

  rootDirectoryUrl,
  webServer,
  testPlan,

  signal = new AbortController().signal,
  handleSIGINT = true,
  updateProcessExitCode = true,
  concurrency = false, // TODO: rename parellel
  defaultMsAllocatedPerExecution = 30_000,
  failFast = false,
  // keepRunning: false to ensure runtime is stopped once executed
  // because we have what we wants: execution is completed and
  // we have associated coverage and console output
  // passsing true means all node process and browsers launched stays opened
  // (can eventually be used for debug)
  keepRunning = false,

  githubCheckEnabled = Boolean(process.env.GITHUB_WORKFLOW),
  githubCheckLogLevel,
  githubCheckName = "Jsenv tests",
  githubCheckTitle = "Tests executions",
  githubCheckToken,
  githubCheckRepositoryOwner,
  githubCheckRepositoryName,
  githubCheckCommitSha,

  coverageEnabled = process.argv.includes("--coverage"),
  coverageConfig = {
    "file:///**/node_modules/": false,
    "./**/.*": false,
    "./**/.*/": false,
    "./**/src/**/*.js": true,
    "./**/src/**/*.ts": true,
    "./**/src/**/*.jsx": true,
    "./**/src/**/*.tsx": true,
    "./**/tests/": false,
    "./**/*.test.html": false,
    "./**/*.test.html@*.js": false,
    "./**/*.test.js": false,
    "./**/*.test.mjs": false,
  },
  coverageIncludeMissing = true,
  coverageAndExecutionAllowed = false,
  coverageMethodForNodeJs = process.env.NODE_V8_COVERAGE
    ? "NODE_V8_COVERAGE"
    : "Profiler",
  // - When chromium only -> coverage generated by v8
  // - When chromium + node -> coverage generated by v8 are merged
  // - When firefox only -> coverage generated by babel+istanbul
  // - When chromium + firefox
  //   -> by default only coverage from chromium is used
  //   and a warning is logged according to coverageV8ConflictWarning
  //   -> to collect coverage from both browsers, pass coverageMethodForBrowsers: "istanbul"
  coverageMethodForBrowsers, // undefined | "playwright" | "istanbul"
  coverageV8ConflictWarning = true,
  coverageTempDirectoryUrl,
  // skip empty means empty files won't appear in the coverage reports (json and html)
  coverageReportSkipEmpty = false,
  // skip full means file with 100% coverage won't appear in coverage reports (json and html)
  coverageReportSkipFull = false,
  coverageReportTextLog = true,
  coverageReportJson = process.env.CI,
  coverageReportJsonFileUrl,
  coverageReportHtml = !process.env.CI,
  coverageReportHtmlDirectoryUrl,

  reporters = [],
  ...rest
}) => {
  const teardownCallbackSet = new Set();

  const operation = Abort.startOperation();
  operation.addAbortSignal(signal);
  if (handleSIGINT) {
    operation.addAbortSource((abort) => {
      return raceProcessTeardownEvents(
        {
          SIGINT: true,
        },
        () => {
          logger.debug(`SIGINT abort`);
          abort();
        },
      );
    });
  }

  let logger;
  let someNeedsServer = false;
  let someHasCoverageV8 = false;
  let someNodeRuntime = false;
  const runtimes = {};
  // param validation
  {
    const unexpectedParamNames = Object.keys(rest);
    if (unexpectedParamNames.length > 0) {
      throw new TypeError(
        `${unexpectedParamNames.join(",")}: there is no such param`,
      );
    }
    rootDirectoryUrl = assertAndNormalizeDirectoryUrl(
      rootDirectoryUrl,
      "rootDirectoryUrl",
    );
    if (!existsSync(new URL(rootDirectoryUrl))) {
      throw new Error(`ENOENT on rootDirectoryUrl at ${rootDirectoryUrl}`);
    }
    if (typeof testPlan !== "object") {
      throw new Error(`testPlan must be an object, got ${testPlan}`);
    }

    logger = createLogger({ logLevel });

    for (const filePattern of Object.keys(testPlan)) {
      const filePlan = testPlan[filePattern];
      if (!filePlan) continue;
      for (const executionName of Object.keys(filePlan)) {
        const executionConfig = filePlan[executionName];
        const { runtime } = executionConfig;
        if (!runtime || runtime.disabled) {
          continue;
        }
        runtimes[runtime.name] = runtime.version;
        if (runtime.type === "browser") {
          if (runtime.capabilities && runtime.capabilities.coverageV8) {
            someHasCoverageV8 = true;
          }
          someNeedsServer = true;
        }
        if (runtime.type === "node") {
          someNodeRuntime = true;
        }
      }
    }

    if (someNeedsServer) {
      await assertAndNormalizeWebServer(webServer, {
        signal: operation.signal,
        teardownCallbackSet,
        logger,
      });
    }

    if (githubCheckEnabled && !process.env.GITHUB_TOKEN) {
      githubCheckEnabled = false;
      const suggestions = [];
      if (process.env.GITHUB_WORKFLOW_REF) {
        const workflowFileRef = process.env.GITHUB_WORKFLOW_REF;
        const refsIndex = workflowFileRef.indexOf("@refs/");
        // see "GITHUB_WORKFLOW_REF" in https://docs.github.com/en/actions/learn-github-actions/variables#default-environment-variables
        const workflowFilePath =
          refsIndex === -1
            ? workflowFileRef
            : workflowFileRef.slice(0, refsIndex);
        suggestions.push(`Pass github token in ${workflowFilePath} during job "${process.env.GITHUB_JOB}"
\`\`\`yml
env:
  GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}
\`\`\``);
      }
      suggestions.push(`Disable github check with githubCheckEnabled: false`);
      logger.warn(
        `${
          UNICODE.WARNING
        } githubCheckEnabled but process.env.GITHUB_TOKEN is missing.
Integration with Github check API is disabled
To fix this warning:
- ${suggestions.join("\n- ")}
`,
      );
    }
    if (githubCheckEnabled) {
      const githubCheckInfoFromEnv = process.env.GITHUB_WORKFLOW
        ? readGitHubWorkflowEnv()
        : {};
      githubCheckToken = githubCheckToken || githubCheckInfoFromEnv.githubToken;
      githubCheckRepositoryOwner =
        githubCheckRepositoryOwner || githubCheckInfoFromEnv.repositoryOwner;
      githubCheckRepositoryName =
        githubCheckRepositoryName || githubCheckInfoFromEnv.repositoryName;
      githubCheckCommitSha =
        githubCheckCommitSha || githubCheckInfoFromEnv.commitSha;
    }

    if (coverageEnabled) {
      if (coverageMethodForBrowsers === undefined) {
        coverageMethodForBrowsers = someHasCoverageV8
          ? "playwright"
          : "istanbul";
      }
      if (typeof coverageConfig !== "object") {
        throw new TypeError(
          `coverageConfig must be an object, got ${coverageConfig}`,
        );
      }
      if (!coverageAndExecutionAllowed) {
        const associationsForExecute = URL_META.resolveAssociations(
          { execute: testPlan },
          "file:///",
        );
        const associationsForCover = URL_META.resolveAssociations(
          { cover: coverageConfig },
          "file:///",
        );
        const patternsMatchingCoverAndExecute = Object.keys(
          associationsForExecute.execute,
        ).filter((testPlanPattern) => {
          const { cover } = URL_META.applyAssociations({
            url: testPlanPattern,
            associations: associationsForCover,
          });
          return cover;
        });
        if (patternsMatchingCoverAndExecute.length) {
          // It would be strange, for a given file to be both covered and executed
          throw new Error(
            createDetailedMessage(
              `some file will be both covered and executed`,
              {
                patterns: patternsMatchingCoverAndExecute,
              },
            ),
          );
        }
      }

      if (coverageTempDirectoryUrl === undefined) {
        coverageTempDirectoryUrl = new URL(
          "./.coverage/tmp/",
          rootDirectoryUrl,
        );
      } else {
        coverageTempDirectoryUrl = assertAndNormalizeDirectoryUrl(
          coverageTempDirectoryUrl,
          "coverageTempDirectoryUrl",
        );
      }
      if (coverageReportJson) {
        if (coverageReportJsonFileUrl === undefined) {
          coverageReportJsonFileUrl = new URL(
            "./.coverage/coverage.json",
            rootDirectoryUrl,
          );
        } else {
          coverageReportJsonFileUrl = assertAndNormalizeFileUrl(
            coverageReportJsonFileUrl,
            "coverageReportJsonFileUrl",
          );
        }
      }
      if (coverageReportHtml) {
        if (coverageReportHtmlDirectoryUrl === undefined) {
          coverageReportHtmlDirectoryUrl = new URL(
            "./.coverage/",
            rootDirectoryUrl,
          );
        } else {
          coverageReportHtmlDirectoryUrl = assertAndNormalizeDirectoryUrl(
            coverageReportHtmlDirectoryUrl,
            "coverageReportHtmlDirectoryUrl",
          );
        }
      }
    }

    if (typeof concurrency !== "boolean" && typeof concurrency !== "number") {
      throw new TypeError(`concurrency must be a boolean or a number`);
    }
  }

  logger.debug(
    createDetailedMessage(`Prepare executing plan`, {
      runtimes: JSON.stringify(runtimes, null, "  "),
    }),
  );

  // param normalization
  {
    if (logFileUrl === undefined) {
      logFileUrl = new URL("./.jsenv/jsenv_tests_output.txt", rootDirectoryUrl);
    }
    if (coverageEnabled) {
      if (Object.keys(coverageConfig).length === 0) {
        logger.warn(
          `coverageConfig is an empty object. Nothing will be instrumented for coverage so your coverage will be empty`,
        );
      }
      if (
        someNodeRuntime &&
        coverageEnabled &&
        coverageMethodForNodeJs === "NODE_V8_COVERAGE"
      ) {
        if (process.env.NODE_V8_COVERAGE) {
          // when runned multiple times, we don't want to keep previous files in this directory
          await ensureEmptyDirectory(process.env.NODE_V8_COVERAGE);
        } else {
          coverageMethodForNodeJs = "Profiler";
          logger.warn(
            createDetailedMessage(
              `process.env.NODE_V8_COVERAGE is required to generate coverage for Node.js subprocesses`,
              {
                "suggestion": `set process.env.NODE_V8_COVERAGE`,
                "suggestion 2": `use coverageMethodForNodeJs: "Profiler". But it means coverage for child_process and worker_thread cannot be collected`,
              },
            ),
          );
        }
      }
    }
    if (concurrency === true) {
      const availableCpus = os.cpus().length;
      concurrency =
        availableCpus > 2
          ? // One CPU is used to run this code so we do availableCpus - 1
            availableCpus - 1
          : 1;
    }
    if (concurrency === false) {
      concurrency = 1;
    }
  }

  reporters.push(
    listReporter({
      logger,
      logDynamic,
      logMemoryHeapUsage,
      logFileUrl,
    }),
  );

  testPlan = {
    "file:///**/node_modules/": null,
    "**/*./": null,
    ...testPlan,
    "**/.jsenv/": null,
  };
  logger.debug(`Generate executions`);

  const testPlanReport = {
    counters: {
      planified: 0,
      remaining: 0,
      aborted: 0,
      timedout: 0,
      failed: 0,
      completed: 0,
      done: 0,
    },
    aborted: false,
    failed: false,
    results: {},
    duration: 0,
    coverage: null,
  };
  const counters = testPlanReport.counters;
  const results = testPlanReport.results;
  const executionPlanifiedSet = new Set();

  // collect files to execute + fill executionPlanifiedSet
  {
    let fileResultArray;
    try {
      fileResultArray = await collectFiles({
        signal,
        directoryUrl: rootDirectoryUrl,
        associations: { testPlan },
        predicate: ({ testPlan }) => testPlan,
      });
    } catch (e) {
      if (Abort.isAbortError(e)) {
        testPlanReport.aborted = true;
        return testPlanReport;
      }
      throw e;
    }
    let index = 0;
    let lastExecution;
    for (const { relativeUrl, meta } of fileResultArray) {
      const filePlan = meta.testPlan;
      for (const executionName of Object.keys(filePlan)) {
        const stepConfig = filePlan[executionName];
        if (stepConfig === null || stepConfig === undefined) {
          continue;
        }
        if (typeof stepConfig !== "object") {
          throw new TypeError(
            createDetailedMessage(
              `found unexpected value in plan, they must be object`,
              {
                ["file relative path"]: relativeUrl,
                ["execution name"]: executionName,
                ["value"]: stepConfig,
              },
            ),
          );
        }
        if (stepConfig.runtime?.disabled) {
          continue;
        }

        const { runtime, runtimeParams } = stepConfig;
        const params = {
          measurePerformance: false,
          collectPerformance: false,
          collectConsole: true,
          allocatedMs: defaultMsAllocatedPerExecution,
          runtime,
          runtimeParams: {
            rootDirectoryUrl,
            webServer,

            coverageEnabled,
            coverageConfig,
            coverageMethodForBrowsers,
            coverageMethodForNodeJs,
            isTestPlan: true,
            fileRelativeUrl: relativeUrl,
            ...runtimeParams,
          },
        };
        const runtimeType = runtime.type;
        const runtimeName = runtime.name;
        const runtimeVersion = runtime.version;

        const execution = {
          counters,
          index,
          isLast: false,
          name: executionName,
          fileRelativeUrl: relativeUrl,
          runtimeType,
          runtimeName,
          runtimeVersion,
          params,

          // will be set by run()
          status: "planified",
          result: {},
        };
        if (typeof params.allocatedMs === "function") {
          params.allocatedMs = params.allocatedMs(execution);
        }

        lastExecution = execution;
        executionPlanifiedSet.add(execution);
        const existingResults = results[relativeUrl];
        if (existingResults) {
          existingResults[execution.name] = execution.result;
        } else {
          results[relativeUrl] = {
            [execution.name]: execution.result,
          };
        }
        index++;
      }
    }
    if (lastExecution) {
      lastExecution.isLast = true;
    }
  }

  counters.planified = executionPlanifiedSet.size;
  logger.debug(`${executionPlanifiedSet.size} executions planned`);
  if (githubCheckEnabled) {
    const githubCheckRun = await startGithubCheckRun({
      logLevel: githubCheckLogLevel,
      githubToken: githubCheckToken,
      repositoryOwner: githubCheckRepositoryOwner,
      repositoryName: githubCheckRepositoryName,
      commitSha: githubCheckCommitSha,
      checkName: githubCheckName,
      checkTitle: githubCheckTitle,
      checkSummary: `${executionPlanifiedSet.size} files will be executed`,
    });
    const annotations = [];
    reporters.push({
      beforeAllExecution: (testPlanReport) => {
        return async () => {
          const title = "Jsenv test results";
          const summaryText = stripAnsi(renderFinalSummary(testPlanReport));
          if (testPlanReport.failed) {
            await githubCheckRun.fail({
              title,
              summary: summaryText,
              annotations,
            });
            return;
          }
          await githubCheckRun.pass({
            title,
            summary: summaryText,
            annotations,
          });
        };
      },
      beforeExecution: (executionInfo) => {
        return () => {
          const { result } = executionInfo;
          const { errors = [] } = result;
          for (const error of errors) {
            const annotation = githubAnnotationFromError(error, {
              rootDirectoryUrl,
              executionInfo,
            });
            annotations.push(annotation);
          }
        };
      },
    });
  }

  const afterAllExecutionCallbackSet = new Set();
  // execute all
  {
    const multipleExecutionsOperation = Abort.startOperation();
    multipleExecutionsOperation.addAbortSignal(signal);
    const failFastAbortController = new AbortController();
    if (failFast) {
      multipleExecutionsOperation.addAbortSignal(
        failFastAbortController.signal,
      );
    }
    let finalizeCoverage;
    if (coverageEnabled) {
      // when runned multiple times, we don't want to keep previous files in this directory
      await ensureEmptyDirectory(coverageTempDirectoryUrl);
      finalizeCoverage = async () => {
        if (multipleExecutionsOperation.signal.aborted) {
          // don't try to do the coverage stuff
          return;
        }
        try {
          if (coverageMethodForNodeJs === "NODE_V8_COVERAGE") {
            takeCoverage();
            // conceptually we don't need coverage anymore so it would be
            // good to call v8.stopCoverage()
            // but it logs a strange message about "result is not an object"
          }
          const coverage = await reportToCoverage(results, {
            signal: multipleExecutionsOperation.signal,
            logger,
            rootDirectoryUrl,
            coverageConfig,
            coverageIncludeMissing,
            coverageMethodForNodeJs,
            coverageV8ConflictWarning,
          });
          testPlanReport.coverage = coverage;
        } catch (e) {
          if (Abort.isAbortError(e)) {
            return;
          }
          throw e;
        }
      };
    }

    const executionRemainingSet = new Set(executionPlanifiedSet);
    const executionRunningSet = new Set();
    const start = async ({ skipCPUCheck } = {}) => {
      // here we decide if we can pick a new execution
      // for now it's just based on concurrency
      // but it will becomes more powerful: available cpu and
      // only if no conflict in "using", etc..
      // to keep in mind: if cpu is too high but there is no execution running
      // then we will still try to execute
      // ideally we should be able to wait before picking next
      // like the cooldown stuff if cpu is too high

      if (multipleExecutionsOperation.signal.aborted) {
        return;
      }
      if (executionRunningSet.size >= concurrency) {
        return;
      }
      if (
        !skipCPUCheck &&
        executionRunningSet.size === 0 &&
        global.cpuIsTooHigh
      ) {
        await new Promise((resolve) => setTimeout(resolve, 500));
        await start({ skipCPUCheck: true });
        return;
      }
      let execution;
      for (const executionCandidate of executionRemainingSet) {
        execution = executionCandidate;
        break;
      }
      if (!execution) {
        return;
      }
      execution.status = "running";
      executionRemainingSet.delete(execution);
      executionRunningSet.add(execution);
      const afterExecutionCallbackSet = new Set();
      for (const beforeExecutionCallback of reporters) {
        const returnValue = beforeExecutionCallback(execution, testPlanReport);
        if (typeof returnValue === "function") {
          afterExecutionCallbackSet.add(returnValue);
        }
      }

      const fileUrl = `${rootDirectoryUrl}${execution.fileRelativeUrl}`;
      if (existsSync(new URL(fileUrl))) {
        const executionResult = await run({
          signal: multipleExecutionsOperation.signal,
          logger,
          allocatedMs: execution.params.allocatedMs,
          keepRunning,
          mirrorConsole: false, // might be executed in parallel: log would be a mess to read
          collectConsole: execution.params.collectConsole,
          coverageEnabled,
          coverageTempDirectoryUrl,
          runtime: execution.params.runtime,
          runtimeParams: execution.params.runtimeParams,
        });
        Object.assign(execution.result, executionResult);
      } else {
        execution.result.status = "failed";
        execution.result.errors = [
          new Error(
            `No file at ${execution.fileRelativeUrl} for execution "${execution.name}"`,
          ),
        ];
      }
      execution.status = "done";
      executionRunningSet.delete(execution);
      counters.done++;
      counters.remaining--;
      if (execution.result.status === "aborted") {
        counters.aborted++;
      } else if (execution.result.status === "timedout") {
        counters.timedout++;
      } else if (execution.result.status === "failed") {
        counters.failed++;
      } else if (execution.result.status === "completed") {
        counters.completed++;
      }
      for (const afterExecutionCallback of afterExecutionCallbackSet) {
        afterExecutionCallback();
      }
      afterExecutionCallbackSet.clear();

      if (execution.result.status !== "completed") {
        testPlanReport.failed = true;
        if (updateProcessExitCode) {
          process.exitCode = 1;
        }
        if (failFast && counters.remaining) {
          logger.info(`"failFast" enabled -> cancel remaining executions`);
          failFastAbortController.abort();
        }
      }
    };
    try {
      const startMs = Date.now();
      for (const reporter of reporters) {
        const beforeAllExecution = reporter.beforeAllExecution;
        if (beforeAllExecution) {
          const returnValue = beforeAllExecution();
          if (typeof returnValue === "function") {
            afterAllExecutionCallbackSet.add(returnValue);
          }
        }
      }
      await start();
      if (!keepRunning) {
        logger.debug("trigger test plan teardown");
        for (const teardownCallback of teardownCallbackSet) {
          await teardownCallback();
        }
        teardownCallbackSet.clear();
      }
      // when execution is aborted, the remaining executions are "cancelled"
      counters.cancelled = counters.total - counters.done;
      testPlanReport.aborted = multipleExecutionsOperation.signal.aborted;
      testPlanReport.duration = Date.now() - startMs;
      if (finalizeCoverage) {
        await finalizeCoverage();
      }
    } finally {
      await multipleExecutionsOperation.end();
    }
  }

  const coverage = testPlanReport.coverage;
  // planCoverage can be null when execution is aborted
  if (coverage) {
    const promises = [];
    // keep this one first because it does ensureEmptyDirectory
    // and in case coverage json file gets written in the same directory
    // it must be done before
    if (coverageEnabled && coverageReportHtml) {
      await ensureEmptyDirectory(coverageReportHtmlDirectoryUrl);
      const htmlCoverageDirectoryIndexFileUrl = `${coverageReportHtmlDirectoryUrl}index.html`;
      logger.info(
        `-> ${urlToFileSystemPath(htmlCoverageDirectoryIndexFileUrl)}`,
      );
      promises.push(
        generateCoverageHtmlDirectory(coverage, {
          rootDirectoryUrl,
          coverageHtmlDirectoryRelativeUrl: urlToRelativeUrl(
            coverageReportHtmlDirectoryUrl,
            rootDirectoryUrl,
          ),
          coverageReportSkipEmpty,
          coverageReportSkipFull,
        }),
      );
    }
    if (coverageEnabled && coverageReportJson) {
      promises.push(
        generateCoverageJsonFile({
          coverage,
          coverageJsonFileUrl: coverageReportJsonFileUrl,
          logger,
        }),
      );
    }
    if (coverageEnabled && coverageReportTextLog) {
      promises.push(
        generateCoverageTextLog(coverage, {
          coverageReportSkipEmpty,
          coverageReportSkipFull,
        }),
      );
    }
    await Promise.all(promises);
  }

  for (const afterAllExecutionCallback of afterAllExecutionCallbackSet) {
    await afterAllExecutionCallback(testPlanReport);
  }
  afterAllExecutionCallbackSet.clear();
  return testPlanReport;
};
