/*
 *
 */

import { cpus, availableParallelism, freemem, totalmem } from "node:os";
import { existsSync } from "node:fs";
import { takeCoverage } from "node:v8";
import stripAnsi from "strip-ansi";
import { Abort, raceProcessTeardownEvents } from "@jsenv/abort";
import { URL_META } from "@jsenv/url-meta";
import {
  ensureEmptyDirectory,
  assertAndNormalizeDirectoryUrl,
  collectFiles,
} from "@jsenv/filesystem";
import { createLogger, createDetailedMessage, UNICODE } from "@jsenv/log";
import {
  startGithubCheckRun,
  readGitHubWorkflowEnv,
} from "@jsenv/github-check-run";

import { startMeasuringCpuUsage } from "../helpers/cpu_usage.js";
import { createCallOrderer } from "../helpers/call_orderer.js";
import { reportToCoverage } from "../coverage/report_to_coverage.js";
import { assertAndNormalizeWebServer } from "./web_server_param.js";
import { githubAnnotationFromError } from "./github_annotation_from_error.js";
import { run } from "./run.js";
import { listReporter, renderFinalSummary } from "./reporters/reporter_list.js";

/**
 * Execute a list of files and log how it goes.
 * @param {Object} testPlanParameters
 * @param {string|url} testPlanParameters.rootDirectoryUrl Directory containing test files;
 * @param {Object} [testPlanParameters.webServer] Web server info; required when executing test on browsers
 * @param {Object} testPlanParameters.testPlan Object associating files with runtimes where they will be executed
 * @param {boolean|number} [testPlanParameters.concurrency=false] Maximum amount of execution running at the same time
 * @param {number} [testPlanParameters.defaultMsAllocatedPerExecution=30000] Milliseconds after which execution is aborted and considered as failed by timeout
 * @param {boolean} [testPlanParameters.failFast=false] Fails immediatly when a test execution fails
 * @param {boolean} [testPlanParameters.logMemoryUsage=false] Add memory heap usage during logs
 * @param {boolean} [testPlanParameters.coverageEnabled=false] Controls if coverage is collected during files executions
 * @param {boolean} [testPlanParameters.coverageV8ConflictWarning=true] Warn when coverage from 2 executions cannot be merged
 * @return {Object} An object containing the result of all file executions
 */
const logsDefault = {
  level: "info",
  dynamic: true,
  memoryUsage: true,
  mockFluctuatingValues: false, // used for snapshot testing logs
  fileUrl: undefined,
};
const githubCheckDefault = {
  logLevel: "info",
  name: "Jsenv tests",
  title: "Tests execution",
  token: undefined,
  repositoryOwner: undefined,
  repositoryName: undefined,
  commitSha: undefined,
};
const coverageDefault = {
  include: {
    "file:///**/node_modules/": false,
    "./**/.*": false,
    "./**/.*/": false,
    "./**/src/**/*.js": true,
    "./**/src/**/*.ts": true,
    "./**/src/**/*.jsx": true,
    "./**/src/**/*.tsx": true,
    "./**/tests/": false,
    "./**/*.test.html": false,
    "./**/*.test.html@*.js": false,
    "./**/*.test.js": false,
    "./**/*.test.mjs": false,
  },
  includeMissing: true,
  coverageAndExecutionAllowed: false,
  methodForNodeJs: process.env.NODE_V8_COVERAGE
    ? "NODE_V8_COVERAGE"
    : "Profiler",
  // - When chromium only -> coverage generated by v8
  // - When chromium + node -> coverage generated by v8 are merged
  // - When firefox only -> coverage generated by babel+istanbul
  // - When chromium + firefox
  //   -> by default only coverage from chromium is used
  //   and a warning is logged according to coverageV8ConflictWarning
  //   -> to collect coverage from both browsers, pass coverageMethodForBrowsers: "istanbul"
  methodForBrowsers: undefined, // undefined | "playwright" | "istanbul"
  v8ConflictWarning: true,
  tempDirectoryUrl: undefined,
};
const parallelDefault = {
  max: "80%", // percentage resolved against the available cpus
  maxCpu: "90%",
  maxMemory: "90%",
};

export const executeTestPlan = async ({
  logs = logsDefault,

  rootDirectoryUrl,
  webServer,
  testPlan,

  signal = new AbortController().signal,
  handleSIGINT = true,
  updateProcessExitCode = true,
  parallel = parallelDefault,
  defaultMsAllocatedPerExecution = 30_000,
  failFast = false,
  // keepRunning: false to ensure runtime is stopped once executed
  // because we have what we wants: execution is completed and
  // we have associated coverage and console output
  // passsing true means all node process and browsers launched stays opened
  // (can eventually be used for debug)
  keepRunning = false,

  githubCheck = process.env.GITHUB_WORKFLOW ? githubCheckDefault : null,
  coverage = process.argv.includes("--coverage") ? coverageDefault : null,

  reporters = [],
  ...rest
}) => {
  const teardownCallbackSet = new Set();

  const operation = Abort.startOperation();
  operation.addAbortSignal(signal);
  if (handleSIGINT) {
    operation.addAbortSource((abort) => {
      return raceProcessTeardownEvents(
        {
          SIGINT: true,
        },
        () => {
          logger.debug(`SIGINT abort`);
          abort();
        },
      );
    });
  }

  const cpuUsage = startMeasuringCpuUsage();
  operation.addEndCallback(cpuUsage.stop);

  let logger;
  const runtimeInfo = {
    someNeedsServer: false,
    someHasCoverageV8: false,
    someNodeRuntime: false,
  };
  // param validation and normalization
  {
    const unexpectedParamNames = Object.keys(rest);
    if (unexpectedParamNames.length > 0) {
      throw new TypeError(`${unexpectedParamNames.join(",")}: no such param`);
    }
    // logs
    {
      if (typeof logs !== "object") {
        throw new TypeError(`logs must be an object, got ${logs}`);
      }
      const unexpectedLogsKeys = Object.keys(logs).filter(
        (key) => !Object.hasOwn(logsDefault, key),
      );
      if (unexpectedLogsKeys.length > 0) {
        throw new TypeError(
          `${unexpectedLogsKeys.join(",")}: no such key on logs`,
        );
      }
      logs = { ...logsDefault, ...logs };
      if (logs.fileUrl === undefined) {
        logs.fileUrl = new URL(
          "./.jsenv/jsenv_tests_output.txt",
          rootDirectoryUrl,
        );
      }
      logger = createLogger({ logLevel: logs.level });
    }
    // rootDirectoryUrl
    {
      rootDirectoryUrl = assertAndNormalizeDirectoryUrl(
        rootDirectoryUrl,
        "rootDirectoryUrl",
      );
      if (!existsSync(new URL(rootDirectoryUrl))) {
        throw new Error(`ENOENT on rootDirectoryUrl at ${rootDirectoryUrl}`);
      }
    }
    // parallel
    {
      if (typeof parallel !== "object") {
        throw new TypeError(`parallel must be an object, got ${parallel}`);
      }
      const unexpectedParallelKeys = Object.keys(parallel).filter(
        (key) => !Object.hasOwn(parallelDefault, key),
      );
      if (unexpectedParallelKeys.length > 0) {
        throw new TypeError(
          `${unexpectedParallelKeys.join(",")}: no such key on parallel`,
        );
      }
      parallel = { ...parallelDefault, ...parallel };
      const assertPercentageAndConvertToRatio = (string) => {
        const lastChar = string[string.length - 1];
        if (lastChar !== "%") {
          throw new TypeError(`string is not a percentage, got ${string}`);
        }
        const percentageString = max.slice(-1);
        const percentageNumber = parseInt(percentageString);
        if (percentageNumber <= 0) {
          return 0;
        }
        if (percentageNumber >= 100) {
          return 1;
        }
        const ratio = Math.floor(percentageNumber / 100);
        return ratio;
      };
      const max = parallel.max;
      if (typeof max === "string") {
        const maxAsRatio = assertPercentageAndConvertToRatio(max);
        const availableCpus = countAvailableCpus();
        parallel.max = maxAsRatio * availableCpus || 1;
      } else if (typeof max !== "number") {
        throw new TypeError(
          `parallel.max must be a number or a percentage, got ${max}`,
        );
      }

      const maxMemory = parallel.maxMemory;
      if (typeof maxMemory === "string") {
        const maxMemoryAsRatio = assertPercentageAndConvertToRatio(maxMemory);
        parallel.maxMemory = maxMemoryAsRatio * totalmem();
      } else if (typeof maxMemory !== "number") {
        throw new TypeError(
          `parallel.maxMemory must be a number or a percentage, got ${maxMemory}`,
        );
      }
    }
    // testPlan
    {
      if (typeof testPlan !== "object") {
        throw new Error(`testPlan must be an object, got ${testPlan}`);
      }
      for (const filePattern of Object.keys(testPlan)) {
        const filePlan = testPlan[filePattern];
        if (!filePlan) continue;
        for (const executionName of Object.keys(filePlan)) {
          const executionConfig = filePlan[executionName];
          const { runtime } = executionConfig;
          if (!runtime || runtime.disabled) {
            continue;
          }
          if (runtime.type === "browser") {
            if (runtime.capabilities && runtime.capabilities.coverageV8) {
              runtimeInfo.someHasCoverageV8 = true;
            }
            runtimeInfo.someNeedsServer = true;
          }
          if (runtime.type === "node") {
            runtimeInfo.someNodeRuntime = true;
          }
        }
      }
      testPlan = {
        "file:///**/node_modules/": null,
        "**/*./": null,
        ...testPlan,
        "**/.jsenv/": null, // ensure it's impossible to look for ".jsenv/"
      };
    }
    // webServer
    if (runtimeInfo.someNeedsServer) {
      await assertAndNormalizeWebServer(webServer, {
        signal: operation.signal,
        teardownCallbackSet,
        logger,
      });
    }
    // githubCheck
    {
      if (githubCheck && !process.env.GITHUB_TOKEN) {
        githubCheck = false;
        const suggestions = [];
        if (process.env.GITHUB_WORKFLOW_REF) {
          const workflowFileRef = process.env.GITHUB_WORKFLOW_REF;
          const refsIndex = workflowFileRef.indexOf("@refs/");
          // see "GITHUB_WORKFLOW_REF" in https://docs.github.com/en/actions/learn-github-actions/variables#default-environment-variables
          const workflowFilePath =
            refsIndex === -1
              ? workflowFileRef
              : workflowFileRef.slice(0, refsIndex);
          suggestions.push(`Pass github token in ${workflowFilePath} during job "${process.env.GITHUB_JOB}"
\`\`\`yml
env:
  GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}
\`\`\``);
        }
        suggestions.push(`Disable github check with githubCheck: false`);
        logger.warn(
          `${UNICODE.WARNING} githubCheck requires process.env.GITHUB_TOKEN.
Integration with Github check API is disabled
To fix this warning:
- ${suggestions.join("\n- ")}
`,
        );
      }
      if (githubCheck) {
        if (typeof githubCheck !== "object") {
          throw new TypeError(`coverage must be an object, got ${coverage}`);
        }
        const unexpectedKeys = Object.keys(githubCheck).filter(
          (key) => !Object.hasOwn(githubCheckDefault, key),
        );
        if (unexpectedKeys.length > 0) {
          throw new TypeError(
            `${unexpectedKeys.join(",")}: no such key on githubCheck`,
          );
        }

        const githubCheckInfoFromEnv = process.env.GITHUB_WORKFLOW
          ? readGitHubWorkflowEnv()
          : {};
        githubCheck = { ...githubCheckDefault, githubCheck };
        if (githubCheck.token === undefined) {
          githubCheck.token = githubCheckInfoFromEnv.githubToken;
        }
        if (githubCheck.repositoryOwner === undefined) {
          githubCheck.repositoryOwner = githubCheckInfoFromEnv.repositoryOwner;
        }
        if (githubCheck.repositoryName === undefined) {
          githubCheck.repositoryName = githubCheckInfoFromEnv.repositoryName;
        }
        if (githubCheck.commitSha === undefined) {
          githubCheck.commitSha = githubCheckInfoFromEnv.commitSha;
        }
      }
    }
    // coverage
    if (coverage) {
      if (typeof coverage !== "object") {
        throw new TypeError(`coverage must be an object, got ${coverage}`);
      }
      const unexpectedKeys = Object.keys(coverage).filter(
        (key) => !Object.hasOwn(coverageDefault, key),
      );
      if (unexpectedKeys.length > 0) {
        throw new TypeError(
          `${unexpectedKeys.join(",")}: no such key on coverage`,
        );
      }
      coverage = { ...coverageDefault, coverage };
      if (typeof coverage.include !== "object") {
        throw new TypeError(
          `coverage.include must be an object, got ${coverage.include}`,
        );
      }
      if (Object.keys(coverage.include).length === 0) {
        logger.warn(
          `coverageConfig is an empty object. Nothing will be instrumented for coverage so your coverage will be empty`,
        );
      }
      if (coverage.methodForBrowsers === undefined) {
        coverage.methodForBrowsers = runtimeInfo.someHasCoverageV8
          ? "playwright"
          : "istanbul";
      }
      if (
        runtimeInfo.someNodeRuntime &&
        coverage.methodForNodeJs === "NODE_V8_COVERAGE"
      ) {
        if (process.env.NODE_V8_COVERAGE) {
          // when runned multiple times, we don't want to keep previous files in this directory
          await ensureEmptyDirectory(process.env.NODE_V8_COVERAGE);
        } else {
          coverage.methodForNodeJs = "Profiler";
          logger.warn(
            createDetailedMessage(
              `process.env.NODE_V8_COVERAGE is required to generate coverage for Node.js subprocesses`,
              {
                "suggestion": `set process.env.NODE_V8_COVERAGE`,
                "suggestion 2": `use coverage.methodForNodeJs: "Profiler". But it means coverage for child_process and worker_thread cannot be collected`,
              },
            ),
          );
        }
      }
      if (!coverage.coverageAndExecutionAllowed) {
        const associationsForExecute = URL_META.resolveAssociations(
          { execute: testPlan },
          "file:///",
        );
        const associationsForCover = URL_META.resolveAssociations(
          { cover: coverage.include },
          "file:///",
        );
        const patternsMatchingCoverAndExecute = Object.keys(
          associationsForExecute.execute,
        ).filter((testPlanPattern) => {
          const { cover } = URL_META.applyAssociations({
            url: testPlanPattern,
            associations: associationsForCover,
          });
          return cover;
        });
        if (patternsMatchingCoverAndExecute.length) {
          // It would be strange, for a given file to be both covered and executed
          throw new Error(
            createDetailedMessage(
              `some file will be both covered and executed`,
              {
                patterns: patternsMatchingCoverAndExecute,
              },
            ),
          );
        }
      }
      if (coverage.tempDirectoryUrl === undefined) {
        coverage.tempDirectoryUrl = new URL(
          "./.coverage/tmp/",
          rootDirectoryUrl,
        );
      } else {
        coverage.tempDirectoryUrl = assertAndNormalizeDirectoryUrl(
          coverage.tempDirectoryUrl,
          "coverageTempDirectoryUrl",
        );
      }
    }
  }

  reporters.push(
    listReporter({
      logger,
      logs,
    }),
  );
  const testPlanInfo = {
    rootDirectoryUrl: String(rootDirectoryUrl),
    groups: {},
    counters: {
      planified: 0,
      remaining: 0,
      executing: 0,
      executed: 0,

      aborted: 0,
      timedout: 0,
      failed: 0,
      completed: 0,
    },
    aborted: false,
    failed: false,
    results: {},
    duration: 0,
    coverage: null,
  };
  const groups = testPlanInfo.groups;
  const counters = testPlanInfo.counters;
  const countersInOrder = { ...counters };
  const results = testPlanInfo.results;

  const executionPlanifiedSet = new Set();

  // collect files to execute + fill executionPlanifiedSet
  {
    let fileResultArray;
    try {
      fileResultArray = await collectFiles({
        signal,
        directoryUrl: rootDirectoryUrl,
        associations: { testPlan },
        predicate: ({ testPlan }) => testPlan,
      });
    } catch (e) {
      if (Abort.isAbortError(e)) {
        testPlanInfo.aborted = true;
        return testPlanInfo;
      }
      throw e;
    }
    let index = 0;
    let lastExecution;
    const fileExecutionCountMap = new Map();
    for (const { relativeUrl, meta } of fileResultArray) {
      const filePlan = meta.testPlan;
      for (const groupName of Object.keys(filePlan)) {
        const stepConfig = filePlan[groupName];
        if (stepConfig === null || stepConfig === undefined) {
          continue;
        }
        if (typeof stepConfig !== "object") {
          throw new TypeError(
            createDetailedMessage(
              `found unexpected value in plan, they must be object`,
              {
                ["file relative path"]: relativeUrl,
                ["group"]: groupName,
                ["value"]: stepConfig,
              },
            ),
          );
        }
        if (stepConfig.runtime?.disabled) {
          continue;
        }

        const { runtime, runtimeParams } = stepConfig;
        const params = {
          measureMemoryUsage: logs.memoryUsage,
          measurePerformance: false,
          collectPerformance: false,
          collectConsole: true,
          allocatedMs: defaultMsAllocatedPerExecution,
          runtime,
          runtimeParams: {
            rootDirectoryUrl,
            webServer,
            teardownCallbackSet,

            coverageEnabled: Boolean(coverage),
            coverageConfig: coverage?.include,
            coverageMethodForBrowsers: coverage?.methodForBrowsers,
            coverageMethodForNodeJs: coverage?.methodForNodeJs,
            isTestPlan: true,
            fileRelativeUrl: relativeUrl,
            ...runtimeParams,
          },
        };
        const runtimeType = runtime.type;
        const runtimeName = runtime.name;
        const runtimeVersion = runtime.version;

        let fileExecutionCount;
        if (fileExecutionCountMap.has(relativeUrl)) {
          fileExecutionCount = fileExecutionCountMap.get(relativeUrl) + 1;
          fileExecutionCountMap.set(relativeUrl, fileExecutionCount);
        } else {
          fileExecutionCount = 1;
          fileExecutionCountMap.set(relativeUrl, fileExecutionCount);
        }

        const execution = {
          counters,
          countersInOrder,
          index,
          isLast: false,
          group: groupName,
          fileRelativeUrl: relativeUrl,
          fileExecutionIndex: fileExecutionCount - 1,
          fileExecutionCount: null,
          runtimeType,
          runtimeName,
          runtimeVersion,
          params,

          // will be set by run()
          status: "planified",
          result: {},
        };
        if (typeof params.allocatedMs === "function") {
          params.allocatedMs = params.allocatedMs(execution);
        }

        lastExecution = execution;
        executionPlanifiedSet.add(execution);
        const existingResults = results[relativeUrl];
        if (existingResults) {
          existingResults[groupName] = execution.result;
        } else {
          results[relativeUrl] = {
            [groupName]: execution.result,
          };
        }
        const existingGroup = groups[groupName];
        if (existingGroup) {
          groups[groupName].count++;
        } else {
          groups[groupName] = {
            count: 1,
            runtimeType,
            runtimeName,
            runtimeVersion,
          };
        }
        index++;
      }
    }
    fileExecutionCountMap.clear();
    if (lastExecution) {
      lastExecution.isLast = true;
    }
  }

  counters.planified = executionPlanifiedSet.size;
  countersInOrder.planified = executionPlanifiedSet.size;
  if (githubCheck) {
    const githubCheckRun = await startGithubCheckRun({
      logLevel: githubCheck.logLevel,
      githubToken: githubCheck.token,
      repositoryOwner: githubCheck.repositoryOwner,
      repositoryName: githubCheck.repositoryName,
      commitSha: githubCheck.commitSha,
      checkName: githubCheck.name,
      checkTitle: githubCheck.title,
      checkSummary: `${executionPlanifiedSet.size} files will be executed`,
    });
    const annotations = [];
    reporters.push({
      beforeAllExecution: (testPlanInfo) => {
        return async () => {
          const title = "Jsenv test results";
          const summaryText = stripAnsi(renderFinalSummary(testPlanInfo));
          if (testPlanInfo.failed) {
            await githubCheckRun.fail({
              title,
              summary: summaryText,
              annotations,
            });
            return;
          }
          await githubCheckRun.pass({
            title,
            summary: summaryText,
            annotations,
          });
        };
      },
      beforeExecution: (executionInfo) => {
        return () => {
          const { result } = executionInfo;
          const { errors = [] } = result;
          for (const error of errors) {
            const annotation = githubAnnotationFromError(error, {
              rootDirectoryUrl,
              executionInfo,
            });
            annotations.push(annotation);
          }
        };
      },
    });
  }

  const afterAllExecutionCallbackSet = new Set();
  // execute all
  {
    const multipleExecutionsOperation = Abort.startOperation();
    multipleExecutionsOperation.addAbortSignal(signal);
    const failFastAbortController = new AbortController();
    if (failFast) {
      multipleExecutionsOperation.addAbortSignal(
        failFastAbortController.signal,
      );
    }
    let finalizeCoverage;
    if (coverage) {
      // when runned multiple times, we don't want to keep previous files in this directory
      await ensureEmptyDirectory(coverage.tempDirectoryUrl);
      finalizeCoverage = async () => {
        if (multipleExecutionsOperation.signal.aborted) {
          // don't try to do the coverage stuff
          return;
        }
        try {
          if (coverage.methodForNodeJs === "NODE_V8_COVERAGE") {
            takeCoverage();
            // conceptually we don't need coverage anymore so it would be
            // good to call v8.stopCoverage()
            // but it logs a strange message about "result is not an object"
          }
          const testPlanCoverage = await reportToCoverage(results, {
            signal: multipleExecutionsOperation.signal,
            logger,
            rootDirectoryUrl,
            coverageConfig: coverage.include,
            coverageIncludeMissing: coverage.includeMissing,
            coverageMethodForNodeJs: coverage.methodForNodeJs,
            coverageV8ConflictWarning: coverage.v8ConflictWarning,
          });
          testPlanInfo.coverage = testPlanCoverage;
        } catch (e) {
          if (Abort.isAbortError(e)) {
            return;
          }
          throw e;
        }
      };
    }

    const callWhenPreviousExecutionAreDone = createCallOrderer();

    const executionRemainingSet = new Set(executionPlanifiedSet);
    const executionExecutingSet = new Set();
    const start = async (execution) => {
      execution.fileExecutionCount = Object.keys(
        testPlanInfo.results[execution.fileRelativeUrl],
      ).length;
      mutateCountersBeforeExecutionStarts(counters, execution);
      mutateCountersBeforeExecutionStarts(countersInOrder, execution);

      execution.status = "executing";
      executionRemainingSet.delete(execution);
      executionExecutingSet.add(execution);
      const afterExecutionCallbackSet = new Set();
      const afterExecutionInOrderCallbackSet = new Set();
      for (const reporter of reporters) {
        const { beforeExecution } = reporter;
        if (beforeExecution) {
          const returnValue = beforeExecution(execution, testPlanInfo);
          if (typeof returnValue === "function") {
            afterExecutionCallbackSet.add(returnValue);
          }
        }
        const { beforeExecutionInOrder } = reporter;
        if (beforeExecutionInOrder) {
          const returnValue = beforeExecutionInOrder(execution, testPlanInfo);
          if (typeof returnValue === "function") {
            afterExecutionInOrderCallbackSet.add(returnValue);
          }
        }
      }
      const executionResult = await run({
        ...execution.params,
        signal: multipleExecutionsOperation.signal,
        logger,
        keepRunning,
        mirrorConsole: false, // might be executed in parallel: log would be a mess to read
        coverageEnabled: Boolean(coverage),
        coverageTempDirectoryUrl: coverage?.tempDirectoryUrl,
      });
      Object.assign(execution.result, executionResult);
      execution.status = "executed";
      executionExecutingSet.delete(execution);
      mutateCountersAfterExecutionEnds(counters, execution);
      if (execution.result.status !== "completed") {
        testPlanInfo.failed = true;
        if (updateProcessExitCode) {
          process.exitCode = 1;
        }
      }

      for (const afterExecutionCallback of afterExecutionCallbackSet) {
        afterExecutionCallback();
      }
      afterExecutionCallbackSet.clear();
      callWhenPreviousExecutionAreDone(execution.index, () => {
        mutateCountersAfterExecutionEnds(countersInOrder, execution);
        for (const afterExecutionInOrderCallback of afterExecutionInOrderCallbackSet) {
          afterExecutionInOrderCallback();
        }
        afterExecutionInOrderCallbackSet.clear();
      });

      if (testPlanInfo.failed && failFast && counters.remaining) {
        logger.info(`"failFast" enabled -> cancel remaining executions`);
        failFastAbortController.abort();
      }
    };
    const startAsMuchAsPossible = async () => {
      const promises = [];
      // eslint-disable-next-line no-constant-condition
      while (true) {
        multipleExecutionsOperation.throwIfAborted();
        if (executionRemainingSet.size === 0) {
          break;
        }
        if (executionExecutingSet.size >= parallel.max) {
          break;
        }

        if (
          // starting execution in parallel is limited by
          // cpu and memory only when trying to parallelize
          // if nothing is executing these limitations don't apply
          executionExecutingSet.size > 0
        ) {
          const availableMemory = freemem();
          const totalMemory = totalmem();
          const usedMemory = totalMemory - availableMemory;
          if (usedMemory > parallel.maxMemory) {
            // retry after Xms in case memory usage decreases
            const promise = (async () => {
              await multipleExecutionsOperation.wait(200);
              await startAsMuchAsPossible();
            })();
            promises.push(promise);
          }

          if (cpuUsage.overall.active > parallel.maxCpu) {
            // retry after Xms in case cpu usage decreases
            const promise = (async () => {
              await multipleExecutionsOperation.wait(200);
              await startAsMuchAsPossible();
            })();
            promises.push(promise);
            break;
          }
        }

        let execution;
        for (const executionCandidate of executionRemainingSet) {
          // TODO: this is where we'll check if it can be executed
          // according to upcoming "using" execution param
          execution = executionCandidate;
          break;
        }
        if (execution) {
          promises.push(start(execution));
        }
      }
      if (promises.length) {
        await Promise.all(promises);
        promises.length = 0;
      }
    };

    try {
      const startMs = Date.now();
      for (const reporter of reporters) {
        const beforeAllExecution = reporter.beforeAllExecution;
        if (beforeAllExecution) {
          const returnValue = beforeAllExecution(testPlanInfo);
          if (typeof returnValue === "function") {
            afterAllExecutionCallbackSet.add(returnValue);
          }
        }
      }
      await startAsMuchAsPossible();
      if (!keepRunning) {
        logger.debug("trigger test plan teardown");
        for (const teardownCallback of teardownCallbackSet) {
          await teardownCallback();
        }
        teardownCallbackSet.clear();
      }
      // when execution is aborted, the remaining executions are "cancelled"
      counters.cancelled = counters.planified - counters.executed;
      testPlanInfo.aborted = multipleExecutionsOperation.signal.aborted;
      testPlanInfo.duration = Date.now() - startMs;
      if (finalizeCoverage) {
        await finalizeCoverage();
      }
    } catch (e) {
      if (Abort.isAbortError(e)) {
        testPlanInfo.aborted = true;
      } else {
        throw e;
      }
    } finally {
      await multipleExecutionsOperation.end();
    }
  }

  for (const afterAllExecutionCallback of afterAllExecutionCallbackSet) {
    await afterAllExecutionCallback(testPlanInfo);
  }
  afterAllExecutionCallbackSet.clear();
  return testPlanInfo;
};

const countAvailableCpus = () => {
  if (typeof availableParallelism === "function") {
    return availableParallelism();
  }
  const cpuArray = cpus();
  return cpuArray.length || 1;
};

const mutateCountersBeforeExecutionStarts = (counters) => {
  counters.executing++;
};

const mutateCountersAfterExecutionEnds = (counters, execution) => {
  counters.executing--;
  counters.executed++;
  counters.remaining--;
  if (execution.result.status === "aborted") {
    counters.aborted++;
  } else if (execution.result.status === "timedout") {
    counters.timedout++;
  } else if (execution.result.status === "failed") {
    counters.failed++;
  } else if (execution.result.status === "completed") {
    counters.completed++;
  }
};
